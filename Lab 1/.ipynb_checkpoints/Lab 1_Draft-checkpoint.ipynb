{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# always display the whole dataframe\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.expand_frame_repr', False) \n",
    "# pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>overgeneralized, not helpful to anyone serious...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Great sound and service.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>love this book!!!: this book is a fast read ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>A hugely enjoyable screen version of Rona Jaff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>What an uninteresting hodge-podge. It could ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>@USAirways customer service at its best! Rache...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica Is it normal to receive no repl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>Imagine the worst skits from Saturday Night Li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>This is one of the worst films ever. I like ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>@JetBlue flight attendant Wendi on Flt 127 on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>This film stars, among others, \"SlapChop\" Vinc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>@united This isn't a one time thing either! It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>It seems a lot of IMDB comments on this film a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>I always wondered what happened with that magi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>eye opening: when i think of poetry i put roet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>Mercy the movie, actually starts out as a some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>I like the good and evil battle. I liked Eddie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>Unlike the previous poster, I liked the cellul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>I was looking for this headset for a long time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>@united mobile apps need construction from the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>@united please give special thanks to Aaron in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>I am appalled and dismayed that the Network ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>Phone now holds charge like it did when it was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>I was never a big fan of television until I wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>awful product!: don't buy the badgemaker or th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>Let me state this right from the start. I do N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>@JetBlue it's been a while since I've angry tw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>@VirginAmerica got it. All set - Thanks!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>astonishingly bright and easy to operate: i us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>Exactly what I wanted.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7470</th>\n",
       "      <td>0</td>\n",
       "      <td>original version is amazing, but disney is cra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7471</th>\n",
       "      <td>0</td>\n",
       "      <td>Starts really well, nice intro and build up fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7472</th>\n",
       "      <td>1</td>\n",
       "      <td>Chucky's back...and it's about time! This time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7473</th>\n",
       "      <td>1</td>\n",
       "      <td>The reception is excellent!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7474</th>\n",
       "      <td>1</td>\n",
       "      <td>@JetBlue awesome, thanks!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7475</th>\n",
       "      <td>1</td>\n",
       "      <td>fascinating book: it has been a couple of year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7476</th>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir @cheerUPDATES So you're saying th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7477</th>\n",
       "      <td>1</td>\n",
       "      <td>This is a Laurel &amp; Hardy comedy short with som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7478</th>\n",
       "      <td>1</td>\n",
       "      <td>Excellent wallet type phone case.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7479</th>\n",
       "      <td>1</td>\n",
       "      <td>@USAirways YOU ARE THE BEST!!! FOLLOW ME PLEAS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7480</th>\n",
       "      <td>0</td>\n",
       "      <td>There are places for political commentary in f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7481</th>\n",
       "      <td>1</td>\n",
       "      <td>good product for reasonable price: needed a la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7482</th>\n",
       "      <td>0</td>\n",
       "      <td>in effective bread slicer: the product looks g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7483</th>\n",
       "      <td>1</td>\n",
       "      <td>@SouthwestAir in flight wifi + @TMobile wifi c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7484</th>\n",
       "      <td>1</td>\n",
       "      <td>Gets a signal when other Verizon phones won't.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7485</th>\n",
       "      <td>1</td>\n",
       "      <td>funke collection: let me start by saying that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7486</th>\n",
       "      <td>1</td>\n",
       "      <td>omg !!!!: i've had this book for just a few we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7487</th>\n",
       "      <td>1</td>\n",
       "      <td>A wonderful movie about people. I first saw Fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7488</th>\n",
       "      <td>1</td>\n",
       "      <td>If you are Razr owner...you must have this!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7489</th>\n",
       "      <td>0</td>\n",
       "      <td>doesn't work too well...: bought this because ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7490</th>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir same here. Would appreciate a fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7491</th>\n",
       "      <td>0</td>\n",
       "      <td>What's the point of reviewing a movie like thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7492</th>\n",
       "      <td>0</td>\n",
       "      <td>@Usairways need to learn operations. Sit a pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7493</th>\n",
       "      <td>1</td>\n",
       "      <td>@JetBlue you don't need to cut services, charg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7494</th>\n",
       "      <td>1</td>\n",
       "      <td>@AmericanAir everything's good now brothaaaaaa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7495</th>\n",
       "      <td>1</td>\n",
       "      <td>@USAirways YOU ARE AMAZING!!! FOLLOW ME BACK, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7496</th>\n",
       "      <td>0</td>\n",
       "      <td>@JetBlue we're home, you guys recovered, now w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7497</th>\n",
       "      <td>1</td>\n",
       "      <td>pays for itself in 0 months: i was paying for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7498</th>\n",
       "      <td>1</td>\n",
       "      <td>@AmericanAir continues to win: I've never miss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499</th>\n",
       "      <td>1</td>\n",
       "      <td>Feels like an impressionistic film; if there i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7500 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      score                                               text\n",
       "0         0  overgeneralized, not helpful to anyone serious...\n",
       "1         1                           Great sound and service.\n",
       "2         1  love this book!!!: this book is a fast read ab...\n",
       "3         1  A hugely enjoyable screen version of Rona Jaff...\n",
       "4         0  What an uninteresting hodge-podge. It could ha...\n",
       "5         1  @USAirways customer service at its best! Rache...\n",
       "6         0  @VirginAmerica Is it normal to receive no repl...\n",
       "7         0  Imagine the worst skits from Saturday Night Li...\n",
       "8         0  This is one of the worst films ever. I like ch...\n",
       "9         1  @JetBlue flight attendant Wendi on Flt 127 on ...\n",
       "10        0  This film stars, among others, \"SlapChop\" Vinc...\n",
       "11        0  @united This isn't a one time thing either! It...\n",
       "12        1  It seems a lot of IMDB comments on this film a...\n",
       "13        1  I always wondered what happened with that magi...\n",
       "14        1  eye opening: when i think of poetry i put roet...\n",
       "15        0  Mercy the movie, actually starts out as a some...\n",
       "16        1  I like the good and evil battle. I liked Eddie...\n",
       "17        1  Unlike the previous poster, I liked the cellul...\n",
       "18        1  I was looking for this headset for a long time...\n",
       "19        0  @united mobile apps need construction from the...\n",
       "20        1  @united please give special thanks to Aaron in...\n",
       "21        1  I am appalled and dismayed that the Network ha...\n",
       "22        1  Phone now holds charge like it did when it was...\n",
       "23        1  I was never a big fan of television until I wa...\n",
       "24        0  awful product!: don't buy the badgemaker or th...\n",
       "25        0  Let me state this right from the start. I do N...\n",
       "26        1  @JetBlue it's been a while since I've angry tw...\n",
       "27        1           @VirginAmerica got it. All set - Thanks!\n",
       "28        1  astonishingly bright and easy to operate: i us...\n",
       "29        1                             Exactly what I wanted.\n",
       "...     ...                                                ...\n",
       "7470      0  original version is amazing, but disney is cra...\n",
       "7471      0  Starts really well, nice intro and build up fo...\n",
       "7472      1  Chucky's back...and it's about time! This time...\n",
       "7473      1                        The reception is excellent!\n",
       "7474      1                          @JetBlue awesome, thanks!\n",
       "7475      1  fascinating book: it has been a couple of year...\n",
       "7476      0  @AmericanAir @cheerUPDATES So you're saying th...\n",
       "7477      1  This is a Laurel & Hardy comedy short with som...\n",
       "7478      1                  Excellent wallet type phone case.\n",
       "7479      1  @USAirways YOU ARE THE BEST!!! FOLLOW ME PLEAS...\n",
       "7480      0  There are places for political commentary in f...\n",
       "7481      1  good product for reasonable price: needed a la...\n",
       "7482      0  in effective bread slicer: the product looks g...\n",
       "7483      1  @SouthwestAir in flight wifi + @TMobile wifi c...\n",
       "7484      1     Gets a signal when other Verizon phones won't.\n",
       "7485      1  funke collection: let me start by saying that ...\n",
       "7486      1  omg !!!!: i've had this book for just a few we...\n",
       "7487      1  A wonderful movie about people. I first saw Fo...\n",
       "7488      1        If you are Razr owner...you must have this!\n",
       "7489      0  doesn't work too well...: bought this because ...\n",
       "7490      0  @SouthwestAir same here. Would appreciate a fo...\n",
       "7491      0  What's the point of reviewing a movie like thi...\n",
       "7492      0  @Usairways need to learn operations. Sit a pla...\n",
       "7493      1  @JetBlue you don't need to cut services, charg...\n",
       "7494      1     @AmericanAir everything's good now brothaaaaaa\n",
       "7495      1  @USAirways YOU ARE AMAZING!!! FOLLOW ME BACK, ...\n",
       "7496      0  @JetBlue we're home, you guys recovered, now w...\n",
       "7497      1  pays for itself in 0 months: i was paying for ...\n",
       "7498      1  @AmericanAir continues to win: I've never miss...\n",
       "7499      1  Feels like an impressionistic film; if there i...\n",
       "\n",
       "[7500 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3752\n",
       "0    3748\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set['score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score    0\n",
       "text     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'<.*?>', ' ', text)  # substitute HTML tags with spaces\n",
    "    text = re.sub(r'@[\\w_]+', ' ', text)  # substitute mentions with spaces\n",
    "    text = re.sub(r'http[s]?://\\S+|www\\.\\S+', ' ', text)  # substitute URLs with spaces\n",
    "    text = re.sub(r'[^\\w\\s\\d\\U0001F000-\\U0001F9FF]', ' ', text)  # substitute punctuations with spaces\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set['text'] = training_set['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>overgeneralized  not helpful to anyone serious...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Great sound and service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>love this book     this book is a fast read ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>A hugely enjoyable screen version of Rona Jaff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>What an uninteresting hodge podge  It could ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>customer service at its best  Rachel S   too...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>Is it normal to receive no reply from Centra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>Imagine the worst skits from Saturday Night Li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>This is one of the worst films ever  I like ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>flight attendant Wendi on Flt 127 on 2 17  N...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score                                               text\n",
       "0      0  overgeneralized  not helpful to anyone serious...\n",
       "1      1                           Great sound and service \n",
       "2      1  love this book     this book is a fast read ab...\n",
       "3      1  A hugely enjoyable screen version of Rona Jaff...\n",
       "4      0  What an uninteresting hodge podge  It could ha...\n",
       "5      1    customer service at its best  Rachel S   too...\n",
       "6      0    Is it normal to receive no reply from Centra...\n",
       "7      0  Imagine the worst skits from Saturday Night Li...\n",
       "8      0  This is one of the worst films ever  I like ch...\n",
       "9      1    flight attendant Wendi on Flt 127 on 2 17  N..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score                                                    0\n",
       "text     overgeneralized  not helpful to anyone serious...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features=6000, stop_words='english', ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tfidf_vectorizer.fit_transform(training_set['text'])\n",
    "y_train = training_set['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply grid search\n",
    "param_grid = {'alpha': [0.1, 0.5, 1.0, 2.0]}\n",
    "grid_search = GridSearchCV(MultinomialNB(), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_alpha = grid_search.best_params_['alpha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=2.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classifier = MultinomialNB(alpha=best_alpha)\n",
    "nb_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1252\n",
       "1    1248\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score    0\n",
       "text     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['text'] = test_set['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = tfidf_vectorizer.transform(test_set['text'])\n",
    "y_test = test_set['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nb_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.84      1252\n",
      "           1       0.85      0.83      0.84      1248\n",
      "\n",
      "    accuracy                           0.84      2500\n",
      "   macro avg       0.84      0.84      0.84      2500\n",
      "weighted avg       0.84      0.84      0.84      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_set = pd.read_csv('evaluation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Don't eat or drink here. Rooms okay but noisy....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>***********If you don't appreciate......\\\"The ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>So so happy that I have it a try. Being dairy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>I just moved to the neighborhood, and I LOVE t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I came here yesterday and had great service. S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>So this was my first time here, staff off with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>Do not come here if you want fast service.\\nA ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>Pizza is mega rad. I'm a sucker for chewy, bub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>I took my cat in to be boarded for a few days ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>Made reservation for 7:45 and finally sat down...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score                                               text\n",
       "0      0  Don't eat or drink here. Rooms okay but noisy....\n",
       "1      1  ***********If you don't appreciate......\\\"The ...\n",
       "2      1  So so happy that I have it a try. Being dairy ...\n",
       "3      1  I just moved to the neighborhood, and I LOVE t...\n",
       "4      0  I came here yesterday and had great service. S...\n",
       "5      1  So this was my first time here, staff off with...\n",
       "6      0  Do not come here if you want fast service.\\nA ...\n",
       "7      1  Pizza is mega rad. I'm a sucker for chewy, bub...\n",
       "8      0  I took my cat in to be boarded for a few days ...\n",
       "9      0  Made reservation for 7:45 and finally sat down..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_set.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2518\n",
       "0    2482\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_set['score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score    0\n",
       "text     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_set.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_set['text'] = evaluation_set['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_evaluation = tfidf_vectorizer.transform(evaluation_set['text'])\n",
    "y_evaluation = evaluation_set['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_evaluation = nb_classifier.predict(X_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.839\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.84      2482\n",
      "           1       0.86      0.81      0.84      2518\n",
      "\n",
      "    accuracy                           0.84      5000\n",
      "   macro avg       0.84      0.84      0.84      5000\n",
      "weighted avg       0.84      0.84      0.84      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_evaluation = accuracy_score(y_evaluation, y_pred_evaluation)\n",
    "print(accuracy_evaluation)\n",
    "print(classification_report(y_evaluation, y_pred_evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we do it again, but different parameters for the vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({'a',\n",
       "           'about',\n",
       "           'above',\n",
       "           'across',\n",
       "           'after',\n",
       "           'afterwards',\n",
       "           'again',\n",
       "           'against',\n",
       "           'all',\n",
       "           'almost',\n",
       "           'alone',\n",
       "           'along',\n",
       "           'already',\n",
       "           'also',\n",
       "           'although',\n",
       "           'always',\n",
       "           'am',\n",
       "           'among',\n",
       "           'amongst',\n",
       "           'amoungst',\n",
       "           'amount',\n",
       "           'an',\n",
       "           'and',\n",
       "           'another',\n",
       "           'any',\n",
       "           'anyhow',\n",
       "           'anyone',\n",
       "           'anything',\n",
       "           'anyway',\n",
       "           'anywhere',\n",
       "           'are',\n",
       "           'around',\n",
       "           'as',\n",
       "           'at',\n",
       "           'back',\n",
       "           'be',\n",
       "           'became',\n",
       "           'because',\n",
       "           'become',\n",
       "           'becomes',\n",
       "           'becoming',\n",
       "           'been',\n",
       "           'before',\n",
       "           'beforehand',\n",
       "           'behind',\n",
       "           'being',\n",
       "           'below',\n",
       "           'beside',\n",
       "           'besides',\n",
       "           'between',\n",
       "           'beyond',\n",
       "           'bill',\n",
       "           'both',\n",
       "           'bottom',\n",
       "           'but',\n",
       "           'by',\n",
       "           'call',\n",
       "           'can',\n",
       "           'cannot',\n",
       "           'cant',\n",
       "           'co',\n",
       "           'con',\n",
       "           'could',\n",
       "           'couldnt',\n",
       "           'cry',\n",
       "           'de',\n",
       "           'describe',\n",
       "           'detail',\n",
       "           'do',\n",
       "           'done',\n",
       "           'down',\n",
       "           'due',\n",
       "           'during',\n",
       "           'each',\n",
       "           'eg',\n",
       "           'eight',\n",
       "           'either',\n",
       "           'eleven',\n",
       "           'else',\n",
       "           'elsewhere',\n",
       "           'empty',\n",
       "           'enough',\n",
       "           'etc',\n",
       "           'even',\n",
       "           'ever',\n",
       "           'every',\n",
       "           'everyone',\n",
       "           'everything',\n",
       "           'everywhere',\n",
       "           'except',\n",
       "           'few',\n",
       "           'fifteen',\n",
       "           'fifty',\n",
       "           'fill',\n",
       "           'find',\n",
       "           'fire',\n",
       "           'first',\n",
       "           'five',\n",
       "           'for',\n",
       "           'former',\n",
       "           'formerly',\n",
       "           'forty',\n",
       "           'found',\n",
       "           'four',\n",
       "           'from',\n",
       "           'front',\n",
       "           'full',\n",
       "           'further',\n",
       "           'get',\n",
       "           'give',\n",
       "           'go',\n",
       "           'had',\n",
       "           'has',\n",
       "           'hasnt',\n",
       "           'have',\n",
       "           'he',\n",
       "           'hence',\n",
       "           'her',\n",
       "           'here',\n",
       "           'hereafter',\n",
       "           'hereby',\n",
       "           'herein',\n",
       "           'hereupon',\n",
       "           'hers',\n",
       "           'herself',\n",
       "           'him',\n",
       "           'himself',\n",
       "           'his',\n",
       "           'how',\n",
       "           'however',\n",
       "           'hundred',\n",
       "           'i',\n",
       "           'ie',\n",
       "           'if',\n",
       "           'in',\n",
       "           'inc',\n",
       "           'indeed',\n",
       "           'interest',\n",
       "           'into',\n",
       "           'is',\n",
       "           'it',\n",
       "           'its',\n",
       "           'itself',\n",
       "           'keep',\n",
       "           'last',\n",
       "           'latter',\n",
       "           'latterly',\n",
       "           'least',\n",
       "           'less',\n",
       "           'ltd',\n",
       "           'made',\n",
       "           'many',\n",
       "           'may',\n",
       "           'me',\n",
       "           'meanwhile',\n",
       "           'might',\n",
       "           'mill',\n",
       "           'mine',\n",
       "           'more',\n",
       "           'moreover',\n",
       "           'most',\n",
       "           'mostly',\n",
       "           'move',\n",
       "           'much',\n",
       "           'must',\n",
       "           'my',\n",
       "           'myself',\n",
       "           'name',\n",
       "           'namely',\n",
       "           'neither',\n",
       "           'never',\n",
       "           'nevertheless',\n",
       "           'next',\n",
       "           'nine',\n",
       "           'no',\n",
       "           'nobody',\n",
       "           'none',\n",
       "           'noone',\n",
       "           'nor',\n",
       "           'not',\n",
       "           'nothing',\n",
       "           'now',\n",
       "           'nowhere',\n",
       "           'of',\n",
       "           'off',\n",
       "           'often',\n",
       "           'on',\n",
       "           'once',\n",
       "           'one',\n",
       "           'only',\n",
       "           'onto',\n",
       "           'or',\n",
       "           'other',\n",
       "           'others',\n",
       "           'otherwise',\n",
       "           'our',\n",
       "           'ours',\n",
       "           'ourselves',\n",
       "           'out',\n",
       "           'over',\n",
       "           'own',\n",
       "           'part',\n",
       "           'per',\n",
       "           'perhaps',\n",
       "           'please',\n",
       "           'put',\n",
       "           'rather',\n",
       "           're',\n",
       "           'same',\n",
       "           'see',\n",
       "           'seem',\n",
       "           'seemed',\n",
       "           'seeming',\n",
       "           'seems',\n",
       "           'serious',\n",
       "           'several',\n",
       "           'she',\n",
       "           'should',\n",
       "           'show',\n",
       "           'side',\n",
       "           'since',\n",
       "           'sincere',\n",
       "           'six',\n",
       "           'sixty',\n",
       "           'so',\n",
       "           'some',\n",
       "           'somehow',\n",
       "           'someone',\n",
       "           'something',\n",
       "           'sometime',\n",
       "           'sometimes',\n",
       "           'somewhere',\n",
       "           'still',\n",
       "           'such',\n",
       "           'system',\n",
       "           'take',\n",
       "           'ten',\n",
       "           'than',\n",
       "           'that',\n",
       "           'the',\n",
       "           'their',\n",
       "           'them',\n",
       "           'themselves',\n",
       "           'then',\n",
       "           'thence',\n",
       "           'there',\n",
       "           'thereafter',\n",
       "           'thereby',\n",
       "           'therefore',\n",
       "           'therein',\n",
       "           'thereupon',\n",
       "           'these',\n",
       "           'they',\n",
       "           'thick',\n",
       "           'thin',\n",
       "           'third',\n",
       "           'this',\n",
       "           'those',\n",
       "           'though',\n",
       "           'three',\n",
       "           'through',\n",
       "           'throughout',\n",
       "           'thru',\n",
       "           'thus',\n",
       "           'to',\n",
       "           'together',\n",
       "           'too',\n",
       "           'top',\n",
       "           'toward',\n",
       "           'towards',\n",
       "           'twelve',\n",
       "           'twenty',\n",
       "           'two',\n",
       "           'un',\n",
       "           'under',\n",
       "           'until',\n",
       "           'up',\n",
       "           'upon',\n",
       "           'us',\n",
       "           'very',\n",
       "           'via',\n",
       "           'was',\n",
       "           'we',\n",
       "           'well',\n",
       "           'were',\n",
       "           'what',\n",
       "           'whatever',\n",
       "           'when',\n",
       "           'whence',\n",
       "           'whenever',\n",
       "           'where',\n",
       "           'whereafter',\n",
       "           'whereas',\n",
       "           'whereby',\n",
       "           'wherein',\n",
       "           'whereupon',\n",
       "           'wherever',\n",
       "           'whether',\n",
       "           'which',\n",
       "           'while',\n",
       "           'whither',\n",
       "           'who',\n",
       "           'whoever',\n",
       "           'whole',\n",
       "           'whom',\n",
       "           'whose',\n",
       "           'why',\n",
       "           'will',\n",
       "           'with',\n",
       "           'within',\n",
       "           'without',\n",
       "           'would',\n",
       "           'yet',\n",
       "           'you',\n",
       "           'your',\n",
       "           'yours',\n",
       "           'yourself',\n",
       "           'yourselves'})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_stop_words = text.ENGLISH_STOP_WORDS\n",
    "my_stop_words\n",
    "#we can see that it has a lot of words that it excludes. What would happen if we don't use any stop words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85      1252\n",
      "           1       0.88      0.80      0.84      1248\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      2500\n",
      "   macro avg       0.85      0.84      0.84      2500\n",
      "weighted avg       0.85      0.84      0.84      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#making a new classifier from the test set:\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2))   #removed the max features parameter\n",
    "X_train = tfidf_vectorizer.fit_transform(training_set['text'])\n",
    "y_train = training_set['score']\n",
    "param_grid = {'alpha': [0.1, 0.5, 1.0, 2.0]}\n",
    "grid_search = GridSearchCV(MultinomialNB(), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "nb_classifier = MultinomialNB(alpha=best_alpha)\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "#testing it on the training dataset\n",
    "X_test = tfidf_vectorizer.transform(test_set['text'])\n",
    "y_test = test_set['score']\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#result: classifier is mostly similar in accuracy. Tiny increase from 0.8432 to 0.8444"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now onto the evaluation set, seeing if there is a change there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.92      0.85      2482\n",
      "           1       0.90      0.77      0.83      2518\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      5000\n",
      "   macro avg       0.85      0.84      0.84      5000\n",
      "weighted avg       0.85      0.84      0.84      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation_set = pd.read_csv('evaluation.csv')\n",
    "evaluation_set['text'] = evaluation_set['text'].apply(clean_text)\n",
    "X_evaluation = tfidf_vectorizer.transform(evaluation_set['text'])\n",
    "y_evaluation = evaluation_set['score']\n",
    "y_pred_evaluation = nb_classifier.predict(X_evaluation)\n",
    "accuracy_evaluation = accuracy_score(y_evaluation, y_pred_evaluation)\n",
    "print(accuracy_evaluation)\n",
    "print(classification_report(y_evaluation, y_pred_evaluation))\n",
    "\n",
    "#accuracy again has a minor increase from 0.839 to 0.84. Not really notable. \n",
    "#Thus, removing of the stop words does not have any influence on the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
